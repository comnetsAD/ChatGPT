Fixed-ratio reinforcement schedules reinforce behavior after a predetermined number of responses. For example, Starbucks on campus gives us a free beverage for every 10 drinks purchased in a reusable cup. Once conditioned, animals pause briefly after receiving a reinforcer before resuming a high rate of response. Reinforcers are given according to variable-ratio schedules after an apparent arbitrary number of answers. Lottery games and its unpredictably reinforcing gambling are good examples of rewards based on a changing ratio schedule. Variable-ratio schedules result in high response rates because reinforcers increase as the number of responses increase. Fixed-interval schedules reinforce the first response after a predetermined amount of time. Animals on this schedule tend to respond more frequently as the anticipated reward time approaches. As the delivery date approaches, individuals track their Shein packages more frequently for example. This results in a discontinuous pattern rather than a consistent rate of reaction. Schedules with variable intervals reinforce the initial response after varied time intervals. In variable ratio schedules, the most addictive ,the individual does not know how many replies he must engage in before receiving reward; hence, he will continue to engage in the desired behavior, creating highly stable rates and making the habit highly resistant to extinction.
