I would most likely utilize a transfer learning strategy to develop a machine translation system from Arabic to Finnish with minimal parallel data and a short timescale. One approach would be to use a limited amount of parallel data obtained from the Europarl and UN corpus to fine-tune a pre-trained model such as the Moses MT system or one of the transformer models (e.g. T5, BERT). I would begin by preprocessing and cleaning the data, followed by using parallel data to fine-tune the pre-trained model. Following that, I would utilize the leftover money to collect more parallel data from other sources, such as internet forums or social media platforms, in order to enhance the model's performance. To assess the model's performance, I would utilize metrics such as BLEU, METEOR, and ROUGE to assess the quality of the translations. In addition, I would do human review by having native speakers of both languages examine the translations. Finally, I would use the model to translate a series of phrases and assess the model's ability to retain the content of the sentences to ensure that the translations are not only grammatically accurate but also make sense. It is critical to recognize that reaching excellent performance with such a short time period and minimal resources will be difficult. However, in this scenario, employing transfer learning and fine-tuning using pre-trained models may be an effective strategy to constructing a machine translation system. 